"""PyTorch DIA - Master

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11j4rBN2RB4xsxjHNO5jvHYfgGZXBIAEe

**Brief description**

A GPU accelerated approach for fast kernel (and differential background) solutions. The model image proposed in the Bramich (2008) algorithm is analogous to a very simple CNN, with a single convolutional layer / discrete pixel array (i.e. the kernel) and an added scalar bias (i.e. the differential background). We do not solve for the discrete pixel array directly in the linear least-squares sense. Rather, by making use of PyTorch tensors (GPU compatible multi-dimensional matrices) and neural network architecture, we solve via an efficient gradient-descent directed optimisation.
"""
'''
from google.colab import drive
drive.mount('/content/drive')

# memory footprint support libraries/code
!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi
!pip install gputil
!pip install psutil
!pip install humanize
import psutil
import humanize
import os
import GPUtil as GPU
GPUs = GPU.getGPUs()
# XXX: only one GPU on Colab and isnÃ¢â‚¬â„¢t guaranteed
gpu = GPUs[0]
def printm():
 process = psutil.Process(os.getpid())
 print("Gen RAM Free: " + humanize.naturalsize( psutil.virtual_memory().available ), " | Proc size: " + humanize.naturalsize( process.memory_info().rss))
 print("GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))
printm()
'''

import torch
import numpy as np
import matplotlib.pyplot as plt
import time
from torch import autograd
from scipy.special import i1

#from torch.cuda.amp import autocast
#from torch.cuda.amp import GradScaler


print('PyTorch version:', torch.__version__)
# make sure to enable GPU acceleration!
if torch.cuda.is_available() is True:
  device = 'cuda'
else:
  print('CUDA not available, defaulting to CPU')


def convert_to_tensor(image):
  if type(image) is np.ndarray:
      image = image.astype(np.float32)
      image = torch.tensor(image[None, None, :, :])
  else:
      pass

  return image


def infer_kernel(R, I, maxiter, FIM, convergence_plots, d, ks, speedy, tol, lr_kernel, lr_B, SD_steps, Newton_tol):

    '''
    # Arguments
    * 'R' (numpy.ndarray or torch.tensor): The reference image
    * 'I' (numpy.ndarray or torch.tensor): The data/target image
    * 'NM' (numpy.ndarray or torch.tensor): The noise model 'image'
    * 'init_kernel' (torch.tensor): Initial guess for the PSF-matching kernel
    * 'init_B' (torch.tensor): Initial guess for the differential background parameter
    * 'i' (int): Iteration number i.e. M_i estimate

    # Keyword arguments
    * 'maxiter' (int): Maximum number of iterations for the optimisation
    * 'alpha' (float): Strength of the L2 regularisation penalty
    * 'FIM' (bool): Calculate parameter uncertanties from the Fisher Matrix
    * 'convergence_plots' (bool): Plot parameter estimates vs steps after optimising
    * 'd' (int): Polynomial of degree 'd' for fitting a spatially varying background
    * 'ks' (int): kernel of size ks x ks, needs to be odd
    * speedy (bool): If True, don't bother with linear transformation operation
      i.e. to be used if we're solving for a scalar background parameter
    * tol (float): Minimum relative change in parameter values before claiming convergence
    * lr_kernel (float): Steepest descent learning rate for kernel
    * lr_B (float): Steepest descent learning rate for background parameter(s)
    * SD_steps (int): Number of gradient descent steps to talke before switching to quasi-Newton optimisation
    
    # returns
    * 'kernel' (numpy.ndarray): the (flipped) inferred kernel
    * 'inferred_bkg' (float): B_0 background term
    * 'fit' (numpy.ndarray): the spatially varying background (inferred_bkg == fit if d=0)
    '''
    
    R, I = convert_to_tensor(R), convert_to_tensor(I)
    
    if speedy is True:
      model = torch.nn.Sequential(
          torch.nn.Conv2d(in_channels=1,
                          out_channels=1,
                          kernel_size=ks,
                          padding = np.int((ks/2)-0.5),
                          padding_mode = 'zeros',
                          bias=True

        )
      )

      # Initialise kernel and bias (and bias correction)
      model[0].weight = torch.nn.Parameter(1e-5*torch.ones(model[0].weight.shape, requires_grad=True))
      model[0].bias = torch.nn.Parameter(1e1*torch.ones(model[0].bias.shape, requires_grad=True))
      #offset = torch.nn.Parameter(1e-3 * torch.ones(1))

      #print(offset, model[0].bias)
     
    
    else:
      class model(torch.nn.Module):
          def __init__(self):

              super(model, self).__init__()
              self.conv = torch.nn.Conv2d(in_channels=1,
                              out_channels=1,
                              kernel_size=ks,
                              padding = np.int((ks/2)-0.5),
                              padding_mode = 'zeros',
                              bias=False)
              
              self.poly = torch.nn.Linear(2*d+1, 1, bias=False)
              #self.poly = torch.nn.Linear(500**2, 1, bias=False)
           
          def forward(self, x, A):
              reshaped_size = (1, 1, R[0][0][0].size()[0], R[0][0][0].size()[0])
              y_pred =  torch.add(self.conv(x), torch.reshape(self.poly(A), reshaped_size))
              return y_pred
    
      model = model()

      # Construct the design/weight matrix for the polynomial background fit
      x = np.linspace(-0.5, 0.5, R[0][0][0].size()[0])
      y = np.linspace(-0.5, 0.5, R[0][0][0].size()[0])
      X, Y = np.meshgrid(x, y, copy=False)
      X = X.flatten()
      Y = Y.flatten()
      
      if d == 0:
        A = np.array([X*0+1]).T
        def poly2Dreco(X, Y, c):
          return c[0]
      elif d == 1:
        A = np.array([X*0+1, X, Y]).T      
        def poly2Dreco(X, Y, c):
          return c[0] + X*c[1] + Y*c[2]
      elif d == 2:
        A = np.array([X*0+1, X, Y, X**2, Y**2]).T
        def poly2Dreco(X, Y, c):
          return c[0] + X*c[1] + Y*c[2] + X**2*c[3] + Y**2*c[4]
      elif d == 3:
        A = np.array([X*0+1, X, Y, X**2, Y**2, X**3, Y**3]).T
        def poly2Dreco(X, Y, c):
          return c[0] + X*c[1] + Y*c[2] + X**2*c[3] + Y**2*c[4] + X**3*c[5] + Y**3*c[6]
      else:
        print('Polynomial of d=%d not currenty supported... need to automate this, reverting to d=3' % d)
        A = np.array([X*0+1, X, Y, X**2, Y**2, X**3, Y**3]).T
        def poly2Dreco(X, Y, c):
          return c[0] + X*c[1] + Y*c[2] + X**2*c[3] + Y**2*c[4] + X**3*c[5] + Y**3*c[6]
      
      if torch.cuda.is_available() is True:
        A = torch.tensor(A).to(device).float()
      else:
        A = torch.tensor(A).float()


      model.conv.weight = torch.nn.Parameter(1e-3 * torch.ones(model.conv.weight.shape, requires_grad=True))
      model.poly.weight = torch.nn.Parameter(1* torch.ones(model.poly.weight.shape, requires_grad=True))


    # Move model to GPU
    if torch.cuda.is_available() is True:
      model = model.to(device)
      #offset = offset.to(device).requires_grad_(True)
      #offset = torch.ones(1).to(data.device).detach().requires_grad_(True)
      offset = torch.cuda.FloatTensor([1.5]).requires_grad_(True)
      print(offset.is_leaf)


      #with torch.no_grad():
      #  offset = offset.to(device)

    # And if alpha != 0, construct the Laplacian to add as a prior
    # to penalize the log-likelihood
    alpha = 0
    if alpha != 0.:
        Nk = model[0].weight[0][0].flatten().size()[0]# number of DBFs
        print('Constructing Laplacian for square kernel with %d DBFs' % Nk)
        
        L = np.zeros((Nk, Nk))
        
        centre_bit = np.arange(1, np.sqrt(Nk)-1)
        
        # corners
        L[0][0] = 2
        L[-1][-1] = 2
        L[np.int(np.sqrt(Nk)-1)][np.int(np.sqrt(Nk)-1)] = 2
        L[Nk-np.int(np.sqrt(Nk))][Nk-np.int(np.sqrt(Nk))] = 2
        
        for u in range(0, Nk):
            for v in range(0, Nk):
                # diagonals
                if u == v:
                    # centre bit
                    if np.sqrt(Nk) < u < Nk - np.sqrt(Nk) - 1 and u % np.sqrt(Nk) in centre_bit:
                        L[u][v] = 4
                    
                    # rest of diags are 3
                    elif L[u][v] != 2:
                        L[u][v] = 3
                
                # off-diagonals        
                elif u != v:
                    if u == v+1:
                        if (v+1) % np.sqrt(Nk) != 0:
                            L[u][v] = -1
                            L[v][u] = -1
                            
                    elif u == v + np.sqrt(Nk):
                        L[u][v] = -1
                        L[v][u] = -1
    
    
        # convert L to tensor
        L = torch.from_numpy(L).float()
        # move L to cuda
        if torch.cuda.is_available() is True:
            L = L.to(device)
            
    # target image pixels
    N_dat = I[0][0].flatten().size()[0]

    # Define the loss (our scalar objective function to optimise)
    # Sometimes referred to as the 'cost' in the ML literature
    #sigma0 = 5 # CCD read noise. G=1, F_ij = 1
    sigma, f, gain = 60., 25.8, 300.
    
    ##################################################################################################
    ## as implemented in Salahat et al. 2013 for approximating the modified Bessel function of the first kind
    def I1_vectorised(argument, coeffs):
    
            z0 = argument[argument >= 0]
            z0 = z0[z0 <= 11.5]
            z0 = z0.reshape(len(z0), 1)
        
            z1 = argument[argument > 11.5]
            z1 = z1[z1 <= 20]
            z1 = z1.reshape(len(z1), 1)
        
            z2 = argument[argument > 20]
            z2 = z2[z2 <= 37.25]
            z2 = z2.reshape(len(z2), 1)
        
            z3 = argument[argument > 37.25]
            z3 = z3.reshape(len(z3), 1)
        
            a0, a1, a2, a3 = coeffs[:,0], coeffs[:,2], coeffs[:, 4], coeffs[:,6]
            b0, b1, b2, b3 = coeffs[:,1], coeffs[:,3], coeffs[:, 5], coeffs[:,7]
        
            def linalg(z, a, b):
                expz = torch.exp(z @ b.reshape(1, len(b)))
                ab = a*b
                out = expz @ ab
                return out
        
            out0, out1, out2, out3 = linalg(z0, a0, b0), linalg(z1, a1, b1), linalg(z2, a2, b2), linalg(z3, a3, b3)
        
            out = torch.cat((out0, out1, out2, out3))
        
            return out

    coeffs = torch.Tensor([[0.1682, 0.7536, 0.2667, 0.4710, 0.1121, 0.9807, 2.41e-9, 1.144],
                       [0.1472, 0.9739, 0.4916, -163.40, 0.1055, 0.8672, 0.06745, 0.995],
                       [0.4450, -0.715, 0.1110, 0.9852, -0.00018, 1.0795, 0.05471, 0.5686],
                       [0.2382, 0.2343, 0.1304, 0.8554, 0.00326, 1.0385, 0.07869, 0.946]])

    coeffs = coeffs.to(device)
    #########################################################################
    
    def kronecker_product(t1, t2):
        """
        Computes the Kronecker product between two tensors.
        See https://en.wikipedia.org/wiki/Kronecker_product
        """
        t1_height, t1_width = t1.size()
        t2_height, t2_width = t2.size()
        out_height = t1_height * t2_height
        out_width = t1_width * t2_width

        tiled_t2 = t2.repeat(t1_height, t1_width)
        expanded_t1 = (
            t1.unsqueeze(2)
              .unsqueeze(3)
              .repeat(1, t2_height, t2_width, 1)
              .view(out_height, out_width)
        )

        return expanded_t1 * tiled_t2

    # resising matrix
    def D_nm(n, m):
        
        # build matrices and vectors
        I_m = torch.eye(m)
        I_n = torch.eye(n)
        ones_m = torch.ones((m, 1))
        ones_n = torch.ones((n, 1))
        
        # D
        D1 = kronecker_product(I_n, ones_m.t())
        D2 = kronecker_product(I_m, ones_n)
        print(D1.size(), D2.size())
        D = (D1 @ D2)/m
        
        return D
        
    # resising matrix
    def D_nm_cuda(n, m):
        
        # build matrices and vectors
        I_m = torch.eye(m, device=device)
        I_n = torch.eye(n, device=device)
        ones_m = torch.ones((m, 1), device=device)
        ones_n = torch.ones((n, 1), device=device)
        
        # D
        D1 = kronecker_product(I_n, ones_m.t())
        D2 = kronecker_product(I_m, ones_n)
        #print(D1.size(), D2.size())
        D = (D1 @ D2)/m
        
        return D

    class negative_log_likelihood(torch.nn.Module):
        '''    
        def forward(model, targ, r, f, g):
            ## for convenience, flatten the model and target images and sort by ascending pixel value
            model, targ = model.flatten().sort()[0], targ.flatten().sort()[0]
            pi = torch.from_numpy(np.array(np.pi))
            lam = (f/g)*model
            prob = (1./torch.sqrt(2*pi*r**2)) * torch.exp(-lam - ((f*targ)**2/(2*r**2)))
            ## EM amplification
            targ_pos = targ[targ > 0]
            model_pos = model[targ > 0]
            lam_pos = lam[targ > 0]
            xs = 2*torch.sqrt((f*targ_pos*lam_pos)/g)
            print('xs:', xs)
            print('Maximum z to evaluate for I_1(z):', torch.max(xs))
            print('Minimum z to evaluate for I_1(z):', torch.min(xs))
            bessel = I1_vectorised(xs, coeffs)
            print(bessel.size())
            prob_EM = torch.sqrt(lam_pos/(f*targ_pos*g)) * torch.exp(-lam_pos - ((f*targ_pos)/g)) * bessel
            
            ## add EM amplifiation bit to full pdf
            prob_pos = prob[targ > 0.] + prob_EM
            prob_else = prob[targ <= 0.]
            prob_full = torch.cat((prob_else, prob_pos))
            prob_full = f*prob_full

            #print(prob_full)
            
            #ll = torch.prod(prob_full)
            ll = torch.sum(torch.log(prob_full))
            nll = -ll

            print('nll:', nll)

            return nll
        '''
        # g (e-_EM), electrons generated after the EM amplification
        # n (e-_phot), electron generated before the EM amplification
        # sigma (e-_EM), the standard deviation of the readnoise
        # gain (e-_EM / e-_phot), EM amplification gain
        # f (e-_EM / ADU)
        # counts (ADU) i.e. image pixel values

        #def Heaviside(g):
        #    step = np.zeros(g.shape)
        #    step[g >= 0] = 1
        #    return step

        def forward(model, targ, sigma, f, gain, w, offset):
            
            # resize HR model to LR data image
            # downscale model to lower resolution scene

            n_original = np.int(model[0][0].size()[0])
            n_new = np.int(n_original/1.5)
            #print('n:%d, n_new:%d' % (n_original, n_new))

            # resising matrix
            D = D_nm_cuda(n_original, n_new)
            
            #print(D)
            #print(D.size(), D.type())
            
            
            #model = model.cpu()

            # apply resising operation
            model = D.t() @ model @ D
            
            #model = model.to(device)
            
            
            #print('Re-sized model to LR')
            #print(model.size(), targ.size())
            
            # collapse everything to 1D
            model, targ = model.flatten(), targ.flatten()
            #print('Collapsed everything to 1D')


            # for convenience, sort targ, and realign model so that pixel pairs correspond
            targ, indices = targ.sort()
            model = model[indices]
            #print('targ', torch.min(targ), torch.max(targ))
            #print('model', torch.min(model), torch.max(model))
            # define 'pi' as a tensor
            pi = torch.from_numpy(np.array(np.pi))
            # convert ADU counts to appropriate dimensions
            g = f*(targ - offset) # (e-_EM / ADU) * ADU = e-_EM
            n = (f/gain)*model # (e-_EM / ADU) * (e-_phot / e_EM) * ADU = e-_phot

            #print('g', torch.min(g), torch.max(g))
            #print('n', torch.min(n), torch.max(n))

            ##### gaussian read noise #####
            #pdf_readout = torch.clamp(torch.exp(-n) * (1./torch.sqrt(2*pi*sigma**2)) * torch.exp(-0.5*(g/sigma)**2), min=1e-30, max=1e30)
            pdf_readout = torch.exp(-n) * (1./torch.sqrt(2*pi*sigma**2)) * torch.exp(-0.5*(g/sigma)**2)
            #print('readout:', torch.min(pdf_readout), torch.max(pdf_readout))
            #print(pdf_readout)

            ##### EM gain noise #####
            # only defined for g>0
            g_pos = g[g>0]
            n_pos = n[g>0]

            # require n_pos > 0
            n_pos = torch.clamp(n_pos, min=1e-30)

            # evaluate modified bessel function of first order
            x = 2*torch.sqrt((n_pos*g_pos)/gain)
            bessel = I1_vectorised(x, coeffs)

            # EM pdf
            pdf_EM = torch.exp(-n_pos - (g_pos/gain)) * torch.sqrt(n_pos/(g_pos*gain)) * bessel
            #print('EM:', torch.min(pdf_EM), torch.max(pdf_EM))

            # add EM pdf to readout pdf for g>0 pixels
            pdf_pos = pdf_readout[g > 0] + pdf_EM
            pdf_neg = pdf_readout[g <= 0]

            # plug everything back together and compute the log-likelihood
            pdf = f*torch.cat((pdf_neg, pdf_pos)) # convert to 1/ADU = (e-_EM/ADU) * (1/e-_EM)
            #pdf = torch.clamp(pdf, min=1e-30)
            #print(torch.min(pdf), torch.max(pdf))

            ll = torch.sum(torch.log(pdf))

            # add laplacian prior on kernel pixels
            if alpha != 0.:
                vector = w[0][0].flatten()
                prior = -alpha * N_dat * (vector.t() @ L.t() @ L @ vector)
                ll += prior

            return -ll
    
    # Keep track of the speed to convergence for development's sake
    losses = []
    ts = []


    # prepare optimizers - For (steepest) gradient descent, we use Adam
    # and once we get close to the minimum, we switch to L-BFGS
    if speedy is True:

      optimizer_Adam = torch.optim.Adam([
                      {'params': model[0].weight, 'lr': lr_kernel},
                      {'params': model[0].bias, 'lr': lr_B},
                      {'params': offset, 'lr': 1e-3}
                  ])
                  
    else:

        optimizer_Adam = torch.optim.Adam([
                    {'params': model.conv.weight, 'lr': lr_kernel},
                    {'params': model.poly.weight, 'lr': lr_B}
                ])
                
    
    optimizer_Newton = torch.optim.LBFGS(model.parameters(), tolerance_change=tol, history_size=10, line_search_fn=None)

    # L-BFGS needs to evaulte the scalar objective function multiple times each call, and requires a
    # closure to be fed to opitmizer_Newton
    def closure():
      optimizer_Newton.zero_grad()
      y_pred = model(R)
      loss = negative_log_likelihood.forward(y_pred, I, sigma, f, gain, model[0].weight)
      loss.backward()
      return loss

        
    # Time the optimisation
    start_time_infer = time.time()

    # flag to switch to quasi newton step
    use_Newton = False
    

    torch.set_printoptions(precision=10)
    print('Check dtype of data and weights:')
    print(R.dtype, I.dtype, model[0].weight.dtype, model[0].bias.dtype)
    print('Check size of data and weights:')
    print(R.size(), I.size(), model[0].weight.size(), model[0].bias.size())
    
    ## scaled gradients ###
    #scaler = GradScaler()
    #print(torch.cuda.memory_summary(device)) 
    ## begin optimising ##
    print('Starting optimisation')
    for t in range(maxiter):


        # flag to use steepest decent if relative change in loss
        # not below Newton_tol
        if use_Newton == False:

          '''

          optimizer_Adam.zero_grad()

          
          # Runs the forward pass with autocasting
          with autocast():

            if speedy is True:
              y_pred = model(R)
            else:
              y_pred = model(R, A)
      
          # compute the loss
          loss = negative_log_likelihood.forward(y_pred, I, sigma, f, gain)

          scaler.scale(loss).backward()
          scaler.step(optimizer_Adam)
          # Updates the scale for next iteration
          scaler.update()
          '''
          if speedy is True:
            y_pred = model(R)
          else:
            y_pred = model(R, A)
      
          # compute the loss
          loss = negative_log_likelihood.forward(y_pred, I, sigma, f, gain, model[0].weight, offset)

          if t % 50 == 0:
            print('Iteration:%d, loss=%f, P=%f' % (t, loss.item(), torch.sum(model[0].weight).item()))
            #print(torch.sum(model[0].weight), model[0].bias, offset)
            print(model[0].bias, offset)
          #print(loss.item(), torch.sum(model[0].weight).item(), model[0].bias.item(), offset.item())
         
          # clear gradients, compute gradients, take a single
          # steepest descent step
          optimizer_Adam.zero_grad()
          loss.backward()
          optimizer_Adam.step()


          with torch.no_grad():
            model[0].weight.clamp_(min=0)
            #model[0].bias.clamp_(min=0)

          
          # append loss
          losses.append(loss.detach())
          ts.append(t)
        
        # don't take more than 250 Newton steps
        elif use_Newton == True and t < SD_steps_taken + 250:
          # perform a single optimisation (quasi-Newton) step
          optimizer_Newton.step(closure)

          # compute and append new loss after the update
          # must be a way to improve this.... #
          y_pred = model(R)
          loss = negative_log_likelihood.forward(y_pred, I, sigma, f, gain, model[0].weight)
          losses.append(loss.detach())
          ts.append(t)
          
        else:
          print('Failed to converge!')
          break


        # Convergence reached if less than specified tol and more than 100
        # steps taken (guard against early stopping)
        if speedy is True:
          if t>100 and abs((losses[-1] - losses[-2])/losses[-2]) < tol:
            print('Converged!')
            print('Total steps taken:', t)
            try:
              print('SD steps:', SD_steps_taken)
              print('L-BFGS steps:', t - SD_steps_taken)
            except UnboundLocalError:
                print('SD only')
            break

          elif t>100 and abs((losses[-1] - losses[-2])/losses[-2]) < Newton_tol and use_Newton == False:
            use_Newton = True
            SD_steps_taken = t
            print('Switching to Quasi-Newton step after %d SD steps' % SD_steps_taken)
          elif t == maxiter - 1:
            print('Failed to converge!')
            break
      

    print("--- Finished kernel and background fit in %s seconds ---" % (time.time() - start_time_infer))


    if speedy is True:
      kernel, B = model[0].weight, model[0].bias

    else:
      kernel, B = model.conv.weight, model.poly.weight


    def compute_full_hessian(grads):

      #Note the use of .detach(). In general, computations involving
      #variables that require gradients will keep history.

      grads = torch.cat((grads[0].flatten(), grads[1].flatten()))
      grad = grads.reshape(-1)
      d = len(grad)
      H = torch.zeros((d, d))
      
      t = time.time()
      print('Looping...')
      for i,dl_dthetai in enumerate(grads):
        H_rowi = torch.autograd.grad(dl_dthetai, model.parameters(), retain_graph=True)
        H_rowi = torch.cat((H_rowi[0].flatten(), H_rowi[1].flatten()))
        H[i] = H_rowi.detach()
      print('Looping took %s seconds' % (time.time() - t))
      return H


    def compute_hessian_blockdiags(grads, params):
      H = []
      t = time.time()
      print('Looping...')
      for i, (grad, p) in enumerate(zip(grads, params)):
          grad = grad.reshape(-1)
          d = len(grad)
          dg = torch.zeros((d, d))

          for j, g in enumerate(grad):
              g2 = autograd.grad(g, p, create_graph=True)[0].view(-1)
              dg[j] = g2.detach()

          H.append(dg)
      print('Looping took %s seconds' % (time.time() - t))
      return H

    
    if FIM == True:
      '''
      We're minimizing an approximation to the negative log-likelihood
      So the returned Hessian is equivalent to the observed Fisher
      Information Matrix (i.e. FIM evaluated at MLE)
      '''

      def det_test(matrix):
        sign, logdet = torch.slogdet(matrix)
        if sign.item() <= 0.:
          print('Covariance matrix not positive definite! Sign of determinant:', sign.item())
        elif sign.item() > 0.:
          pass

      def eigenvals_test(matrix):
        eigenvals = torch.eig(matrix)[0]
        if any(eigval <= 0. for eigval in eigenvals[:,0]):
          print('Covariance matrix not positive definite!. Non-positive eigenvalues.1')

      
      def get_stderror(obs_fisher_matrix):
        '''
        Is the estiamted covariance matrix valid?
        A valid covariance matrix has to be positive definite
        Test 1:
        check if det cov_matrix <= 0., cov_matrix is not valid
        Test 2:
        diagnoalise cov_matrix to determine eigenvalues.
        If any of these are <= 0., cov_matrix is not valid
        '''
        cov_matrix = torch.inverse(obs_fisher_matrix)
        print('Covariance Matrix:', cov_matrix)
        det_test(cov_matrix) # Test 1
        eigenvals_test(cov_matrix) # Test 2
        cov_matrix_diagonals = torch.diag(cov_matrix)

        return cov_matrix_diagonals
      '''
      Compute FIM (i.e. Hessian!)
      '''
      
      # Full Hessian #
      if speedy is True:
        y_pred = model(R)
      else:
        y_pred = model(R, A)
      loss = negative_log_likelihood.forward(y_pred, I, sigma, f, gain)
      logloss_grads = autograd.grad(loss, model.parameters(), create_graph=True, retain_graph=True)
      print('Building full Hessian...')
      full_hessian_time = time.time() 
      H = compute_full_hessian(logloss_grads)

      print('---Finished constructing full hessian in %s seconds---' % (time.time() - full_hessian_time))      
      cov_matrix_diags = get_stderror(H)
      print('Cov matrix diagonals:', cov_matrix_diags)
      psf_err, B0_err = torch.sqrt(torch.sum(cov_matrix_diags[0:-(2*d+1)])), torch.sqrt(cov_matrix_diags[-(2*d+1)])
      print('Photometric scaling:', torch.sum(kernel).item(), '+/-', psf_err.item())
      if speedy is True:
        print('B_0:', torch.sum(B[0]).item(), '+/-', B0_err.item())
      else:
        print('B_0:', torch.sum(B[0][0]).item(), '+/-', B0_err.item())


    else:
      print('Photometric scaling:', torch.sum(kernel))
      if speedy is True:
        print('B_0:', torch.sum(B[0]).item())
      else:
        print('B_0:', torch.sum(B[0][0]).item())
 
    if convergence_plots == True:
      plt.plot(ts[1:], np.log(losses[1:]))
      plt.xlabel('Iterations')
      plt.ylabel('log_10(loss)')
      plt.title('log loss vs iterations')
      plt.show()
    

    # flip kernel to correct orientation (as I pass this to conv2d)
    print('Not flipping kernel, as passed to torch.functional.conv2d')
    flipped_kernel = torch.flip(kernel, [2, 3])
    flipped_kernel = flipped_kernel[0][0].cpu().detach().numpy()
    kernel = kernel[0][0].cpu().detach().numpy()
    B = B[0].cpu().detach().numpy()

    if speedy is True:
      B = B.item()

    if d>0:
      X, Y = np.meshgrid(x, y, copy=False)
      B = poly2Dreco(X, Y, B)
    
    return kernel, B, offset.cpu().detach().numpy(), flipped_kernel



def DIA(R,
        I,
        flat,
        read_noise = 0.,
        ks = 15,
        lr_kernel = 1e-2,
        lr_B = 1e1,
        SD_steps = 100,
        Newton_tol = 1e-6,
        poly_degree=0,
        fast=True,
        tol = 1e-5,
        max_iterations = 5000,
        fisher=False,
        show_convergence_plots=False):
  
  '''
  ## Arguments
  * 'R_full' (numpy.ndarray): Input reference image
  * 'I_full'(numpy.ndarray): Input target image
  * 'flat' (numpy.ndarray): provided flat field for the images

  ## Keyword Arguments
  * 'read_noise' (float): detector read noise (ADU), defeault = 0.
  * 'unweighted' (bool): don't bother with a noise model, default=False
  * 'n_samples' (int): If MC sampling, specify how many kernel and background solutions we want, default = 1
  * 'full_image' (bool): Infer kernel for full image or MC sampled subregions, default=True
  * 'display_stamps' (bool): Plot the input reference and target pair (either full image or subregions), default=False
  * 'sky_subtract' (bool): Subtract the median pixel values from the input images, default=False
  * 'iters' (int): Number of iterations (estimates of Model image) to perform, default = 3
  * 'ks' (int): Size of ks x ks kernel **Needs to be odd**, default=15
  * 'lr_kernel' (float): The learning rate for the parameters of the convolution kernel, default=1e-2
  * 'lr_B' (float): The learning rate for the parameters for the differential background solution, default=1e1
  * 'SD_steps' (int): Number of gradient descent steps to talke before switching to quasi-Newton optimisation
  * 'poly_degree' (int): Degree of polynomial for background fit, default=0
  * 'fast' (bool): Use in-built torch.nn.Conv2d function if True, which fits for a scalar background term.
     If False, we'll fit a polynomial of degree 'poly_degree' for the background, which requires an additional
     customised linear transformation operation, which is slower than the in-built function even for 0 degree
     polynomial, default = True.
  * 'tol' (float): Minimum relative change in parameters for claiming convergence of kernel and background fit,
     default = 1e-5
  * 'alpha' (float): Strength of L2 regularisation penalty on kernel solution, default = 0.
  * 'max_iterations' (int): Maximum number of iterations in optimisation, default=5000
  * 'fisher' (bool): Output kernel and background uncertainty estimates calculated from Fisher Matrix, default=False
  * 'show_convergence_plots' (bool): Plot parameter estimates vs steps in optimisation procedure, default=False
  * 'display_D' (bool): Plot the difference image(s), default = False
  * 'k' (int): sigma clip to apply to normalised residuals at each iteration,
     default=5 **WARNING:Highly sensitve to choice of noise model!!
     If you're not sure, set this to be very large to avoid overly severe clipping!**
  * 'precision' (int): Decimal place precision at which we claim convergence of kernel solution,
     default=3 i.e. if change in photometric scale factor at next iteration < 0.001 we've converged
  * 'display_masked_stamps' (bool): Plot the sigma clipped images, default=False
  * 'display_M' (bool): Plot the model image(s)
  * 'display_kernel' (bool): Plot the inferred kernel(s)
  * 'display_B* (bool): Plot the inferred spatially varying background(s)
  
  ## Returns
  * 'kernel' (numpy.ndarray): the convolution kernel
  * 'B' (numpy.ndarray): the differential background
  '''


  start_time_total = time.time()
    
  #### Convert numpy images to tensors and move to GPU
  I, R = convert_to_tensor(I), convert_to_tensor(R)

  time_to_move_to_GPU = time.time()
    
  # Move to GPU if CUDA available
  if torch.cuda.is_available() is True:
    R = R.to(device)
    I = I.to(device)


  print("--- Time to move data onto GPU: %s ---" % (time.time() - time_to_move_to_GPU))



  kernel, B, offset, flipped_kernel = infer_kernel(R, I, 
                                   maxiter=max_iterations,
                                   FIM=fisher,
                                   convergence_plots=show_convergence_plots,
                                   d = poly_degree,
                                   ks = ks,
                                   speedy = fast,
                                   tol = tol,
                                   lr_kernel = lr_kernel,
                                   lr_B = lr_B,
                                   SD_steps = SD_steps,
                                   Newton_tol = Newton_tol)


  print("--- Finished in a total of %s seconds ---" % (time.time() - start_time_total))

  return kernel, B, offset.item(), flipped_kernel






